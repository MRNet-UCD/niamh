{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from dataloader import MRDataset\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "from torchsample.transforms import RandomRotate, RandomTranslate, RandomFlip, ToTensor, Compose, RandomAffine\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import pdb\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MRDataset(list(range(0,1130)), '/home/niamh/Documents/MRNET/data/', \n",
    "                    'acl',\n",
    "                   'axial',\n",
    "                        transform=None)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=False, num_workers=11, drop_last=False)\n",
    "\n",
    "\n",
    "mod =torch.load('/home/niamh/Documents/MRNET/final_lg/con/acl/axial/secondtime/model_fold4_aa_acl_axial_test_auc_0.9714_train_auc_0.9805_val_auc_0.9532_epoch_14_best_test.pth',\n",
    "             map_location=torch.device('cpu'))\n",
    "\n",
    "# hook the feature extractor\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "\n",
    "mod._modules.get('pretrained_model').layer4.register_forward_hook(hook_feature);\n",
    "\n",
    "features_blobs_conv = []\n",
    "def hook_feature2(module, input, output):\n",
    "    features_blobs_conv.append(output.data.cpu().numpy())\n",
    "\n",
    "mod._modules.get('conv').register_forward_hook(hook_feature2);\n",
    "\n",
    "features_blobs_gr = []\n",
    "\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    print(grad_out)\n",
    "    features_blobs_gr.append(grad_out[0].cpu().numpy() )\n",
    "    \n",
    "mod._modules.get('pretrained_model').layer4.register_backward_hook(backward_hook);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)]))\n",
    "    if torch.cuda.is_available():\n",
    "        a = a.cuda()\n",
    "      #  dim = torch.Tensor(dim).cuda()\n",
    "        order_index = order_index.cuda()\n",
    "    return torch.index_select(a, dim, order_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, (image,label, weight) in enumerate(train_loader):\n",
    "      #  optimizer.zero_grad()\n",
    "    if len(str(i)) == 1:\n",
    "        string = '000' + str(i) \n",
    "    elif len(str(i)) == 2:\n",
    "        string = '00' + str(i) \n",
    "    elif len(str(i)) == 3:\n",
    "        string = '0' + str(i) \n",
    "    elif len(str(i)) == 4:\n",
    "        string = str(i) \n",
    "        \n",
    "    task = 'acl'\n",
    "    plane ='axial'\n",
    "    os.mkdir('./cams/' + task + '/' + plane +'/' + string)\n",
    "    label = label[0]\n",
    "    weight = weight[0]\n",
    "    a = np.zeros((1,1))\n",
    "    prediction = mod.forward(image.float())\n",
    "    loss = torch.nn.BCEWithLogitsLoss(weight=weight)(prediction.squeeze(0), label)\n",
    "    loss.backward()\n",
    "    \n",
    "    weights =nn.AdaptiveAvgPool2d(1)(torch.Tensor(features_blobs_gr[i]))\n",
    "    \n",
    "    a = torch.Tensor(features_blobs_conv[i])\n",
    "    x = torch.Tensor(features_blobs[i])\n",
    "    a =  nn.Softmax(2)(a.view(*a.size()[:2], -1)).view_as(a)\n",
    "    m = torch.max(a.flatten(2), 2).values\n",
    "    b= tile(m, 1, 64)\n",
    "    c = a.flatten(2).flatten(1) / b\n",
    "    d = torch.reshape(c, (a.shape[0],512,8,8))\n",
    "    o = x*d \n",
    "    \n",
    "    \n",
    "    gcam = torch.mul(o, weights).sum(dim=1, keepdim=True)\n",
    "    gcam = F.relu(gcam)\n",
    "    gcam = F.interpolate(\n",
    "                gcam, (256,256), mode=\"bilinear\", align_corners=False\n",
    "            )\n",
    "    B, C, H, W = gcam.shape\n",
    "\n",
    "\n",
    "    gcam = gcam.view(B, -1)\n",
    "    gcam -= gcam.min(dim=1, keepdim=True)[0]\n",
    "    gcam /= gcam.max(dim=1, keepdim=True)[0]\n",
    "    gcam = gcam.view(B, H, W)\n",
    "\n",
    "    \n",
    "    for j in range(0, image.shape[1]):\n",
    "        img = image[0][j].numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        heatmap = np.uint8(255 * gcam.numpy()[j])\n",
    "\n",
    "        heatmap = (cv2\n",
    "                    .cvtColor(cv2.applyColorMap(\n",
    "                        cv2.resize(heatmap, (256, 256)),\n",
    "                        cv2.COLORMAP_JET), \n",
    "                               cv2.COLOR_BGR2RGB)\n",
    "                  )\n",
    "        result = heatmap * 0.5 + img * 0.5  \n",
    "\n",
    "        pil_img_cam = Image.fromarray(np.uint8(result))\n",
    "        pil_img_cam.save('./cams/' + task + '/' + plane +'/' + string +'/' +str(j) + '.png')\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grad cams for ACL sagittal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MRDataset(list(range(0,1130)), '/home/niamh/Documents/MRNET/data/', \n",
    "                    'acl',\n",
    "                   'sagittal',\n",
    "                        transform=None)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=False, num_workers=11, drop_last=False)\n",
    "\n",
    "\n",
    "mod =torch.load('/home/niamh/Documents/MRNET/final_lg/con/acl/sagittal/second_time/model_fold0_naa_acl_sagittal_test_auc_0.9285_val_auc_0.8534_train_auc_0.9820_epoch_17.pth',\n",
    "             map_location=torch.device('cpu'))\n",
    "\n",
    "# hook the feature extractor\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "\n",
    "mod._modules.get('pretrained_model').layer4.register_forward_hook(hook_feature);\n",
    "\n",
    "features_blobs_conv = []\n",
    "def hook_feature2(module, input, output):\n",
    "    features_blobs_conv.append(output.data.cpu().numpy())\n",
    "\n",
    "mod._modules.get('conv').register_forward_hook(hook_feature2);\n",
    "\n",
    "features_blobs_gr = []\n",
    "\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    print(grad_out)\n",
    "    features_blobs_gr.append(grad_out[0].cpu().numpy() )\n",
    "    \n",
    "mod._modules.get('pretrained_model').layer4.register_backward_hook(backward_hook);\n",
    "\n",
    "\n",
    "\n",
    "for i, (image,label, weight) in enumerate(train_loader):\n",
    "    if (i <38) & (i>=21 ):\n",
    " \n",
    "      #  optimizer.zero_grad()\n",
    "        if len(str(i)) == 1:\n",
    "            string = '000' + str(i) \n",
    "        elif len(str(i)) == 2:\n",
    "            string = '00' + str(i) \n",
    "        elif len(str(i)) == 3:\n",
    "            string = '0' + str(i) \n",
    "        elif len(str(i)) == 4:\n",
    "            string = str(i) \n",
    "\n",
    "        task = 'acl'\n",
    "        plane ='sagittal'\n",
    "        try:\n",
    "            os.mkdir('./cams/' + task + '/' + plane +'/' + string)\n",
    "        except:\n",
    "            print('')\n",
    "            \n",
    "        label = label[0]\n",
    "        weight = weight[0]\n",
    "        a = np.zeros((1,1))\n",
    "        prediction = mod.forward(image.float())\n",
    "        loss = torch.nn.BCEWithLogitsLoss(weight=weight)(prediction.squeeze(0), label)\n",
    "        loss.backward()\n",
    "\n",
    "        weights =nn.AdaptiveAvgPool2d(1)(torch.Tensor(features_blobs_gr[i-21]))\n",
    "\n",
    "        a = torch.Tensor(features_blobs_conv[i-21])\n",
    "        x = torch.Tensor(features_blobs[i-21])\n",
    "        a =  nn.Softmax(2)(a.view(*a.size()[:2], -1)).view_as(a)\n",
    "        m = torch.max(a.flatten(2), 2).values\n",
    "        b= tile(m, 1, 64)\n",
    "        c = a.flatten(2).flatten(1) / b\n",
    "        d = torch.reshape(c, (a.shape[0],512,8,8))\n",
    "        o = x*d \n",
    "\n",
    "\n",
    "        gcam = torch.mul(o, weights).sum(dim=1, keepdim=True)\n",
    "        gcam = F.relu(gcam)\n",
    "        gcam = F.interpolate(\n",
    "                    gcam, (256,256), mode=\"bilinear\", align_corners=False\n",
    "                )\n",
    "        B, C, H, W = gcam.shape\n",
    "\n",
    "\n",
    "        gcam = gcam.view(B, -1)\n",
    "        gcam -= gcam.min(dim=1, keepdim=True)[0]\n",
    "        gcam /= gcam.max(dim=1, keepdim=True)[0]\n",
    "        gcam = gcam.view(B, H, W)\n",
    "\n",
    "\n",
    "        for j in range(0, image.shape[1]):\n",
    "            img = image[0][j].numpy()\n",
    "            img = img.transpose(1, 2, 0)\n",
    "            heatmap = np.uint8(255 * gcam.numpy()[j])\n",
    "\n",
    "            heatmap = (cv2\n",
    "                        .cvtColor(cv2.applyColorMap(\n",
    "                            cv2.resize(heatmap, (256, 256)),\n",
    "                            cv2.COLORMAP_JET), \n",
    "                                   cv2.COLOR_BGR2RGB)\n",
    "                      )\n",
    "            result = heatmap * 0.5 + img * 0.5  \n",
    "\n",
    "            pil_img_cam = Image.fromarray(np.uint8(result))\n",
    "            pil_img_cam.save('./cams/' + task + '/' + plane +'/' + string +'/' +str(j) + '.png')\n",
    "    elif i > 38:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grad cams for ACL SAGITTAL - not multyplying by attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MRDataset(list(range(0,1130)), '/home/niamh/Documents/MRNET/data/', \n",
    "                    'acl',\n",
    "                   'sagittal',\n",
    "                        transform=None)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=False, num_workers=11, drop_last=False)\n",
    "\n",
    "\n",
    "mod =torch.load('/home/niamh/Documents/MRNET/final_lg/con/acl/sagittal/second_time/model_fold0_naa_acl_sagittal_test_auc_0.9285_val_auc_0.8534_train_auc_0.9820_epoch_17.pth',\n",
    "             map_location=torch.device('cpu'))\n",
    "\n",
    "# hook the feature extractor\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "\n",
    "mod._modules.get('pretrained_model').layer4.register_forward_hook(hook_feature);\n",
    "\n",
    "features_blobs_gr = []\n",
    "\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    print(grad_out)\n",
    "    features_blobs_gr.append(grad_out[0].cpu().numpy() )\n",
    "    \n",
    "mod._modules.get('pretrained_model').layer4.register_backward_hook(backward_hook);\n",
    "\n",
    "\n",
    "for i, (image,label, weight) in enumerate(train_loader):\n",
    "    if (i >38):\n",
    "        break\n",
    "      #  optimizer.zero_grad()\n",
    "    if len(str(i)) == 1:\n",
    "        string = '000' + str(i) \n",
    "    elif len(str(i)) == 2:\n",
    "        string = '00' + str(i) \n",
    "    elif len(str(i)) == 3:\n",
    "        string = '0' + str(i) \n",
    "    elif len(str(i)) == 4:\n",
    "        string = str(i) \n",
    "        \n",
    "    task = 'acl'\n",
    "    plane ='sagittal'\n",
    "    try:\n",
    "        os.mkdir('./cams/' + task + '/' + plane +'2/' + string)\n",
    "    except:\n",
    "        print('')\n",
    "        \n",
    "    label = label[0]\n",
    "    weight = weight[0]\n",
    "    prediction = mod.forward(image.float())\n",
    "    loss = torch.nn.BCEWithLogitsLoss(weight=weight)(prediction.squeeze(0), label)\n",
    "    loss.backward()\n",
    "    \n",
    "    weights =nn.AdaptiveAvgPool2d(1)(torch.Tensor(features_blobs_gr[i]))\n",
    "    \n",
    "    gcam = torch.mul(torch.Tensor(features_blobs[i]), weights).sum(dim=1, keepdim=True)\n",
    "    gcam = F.relu(gcam)\n",
    "    gcam = F.interpolate(\n",
    "                gcam, (256,256), mode=\"bilinear\", align_corners=False\n",
    "            )\n",
    "    B, C, H, W = gcam.shape\n",
    "\n",
    "\n",
    "    gcam = gcam.view(B, -1)\n",
    "    gcam -= gcam.min(dim=1, keepdim=True)[0]\n",
    "    gcam /= gcam.max(dim=1, keepdim=True)[0]\n",
    "    gcam = gcam.view(B, H, W)\n",
    "\n",
    "    \n",
    "    for j in range(0, image.shape[1]):\n",
    "        img = image[0][j].numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        heatmap = np.uint8(255 * gcam.numpy()[j])\n",
    "\n",
    "        heatmap = (cv2\n",
    "                    .cvtColor(cv2.applyColorMap(\n",
    "                        cv2.resize(heatmap, (256, 256)),\n",
    "                        cv2.COLORMAP_JET), \n",
    "                               cv2.COLOR_BGR2RGB)\n",
    "                  )\n",
    "        result = heatmap * 0.5 + img * 0.5  \n",
    "\n",
    "        pil_img_cam = Image.fromarray(np.uint8(result))\n",
    "        pil_img_cam.save('./cams/' + task + '/' + plane +'2/' + string +'/' +str(j) + '.png')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
